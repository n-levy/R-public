
# MovieLens Project Submission
## Nir Levy, January 2022

## Summary
This report describes my work on the MovieLens project, within the Capstone course of Harvardx's Data Science Professional Certificate.  
The goal of the project was to predict ratings provided by users to movies. 
Both users and movies in the test set were included in the training set as well. 
After downloading, arranging and exploring the data (section 2), I evaluated the performance of several prediction models on the training set (section 3).   
The Funk Singular Value Decomposition model (SVDF) performed best, but it took a long time to run, so I decided to use the Popular model which performed  
reasonably well and ran quickly. 
I applied the Popular model to the test set and received a Root Mean Squared Error (RMSE) of 0.856 (section 4).
My main conclusion is that it is important to be aware of the trade-off between performance and speed. (section 5)
Although the SVDF model produced the lowest RMSE, due to my limited processing power it was impractical. 
The 'Popular' model was much faster and produced a reasonable RMSE, so this seemed like a better choice.

### Structure of the report
The report is structured as follows: the first section describes the goal of the analysis. The second section presents some exploratory analysis of the data, and the third section presents some prediction models that I checked out using the training set, before choosing the one that I used for predicting the test set scores (the 'Popular' model). The fourth section presents the results of applying this model on the test set.  
Finally, the fifth section presents the conclusion.

## Table of contents
1. Introduction
2. Downloading and exploring the data
3. Choosing a prediction model
4. Applying the model to the test set
5. Conclusion

## 1. Introduction
### The assignment
The goal of the project was to predict ratings provided by users to movies. Both users and movies in the test set were included in the training set as well. Therefore, the hypothetical scenario is that we already have information about a set of users and a set of movies. However, the information does not cover the ratings given by each user to each movie. It only covers ratings given by each user to a small amount of movies (the matrix in which the rows are users and the columns are movies is very sparse). Based on the ratings that we observe, we wish to predict other ratings within the same set of users and movies.

### The analysis
The key steps of the analysis were as follows:
1. Downloading, arranging and exploring the data (section 2)
2. Evaluating the performance of various prediction models on the training set (section 3)
3. Applying the chosen model ('Popular') to the test set and calculating the RMSE (section 4)

The following sections present these steps and the conclusion.

## 2. Downloading, arranging and exploring the data

I begin by downloading the data, using the code provided by the course.
Since it is provided by the course, I have hidden it in the report. 
See the R script or the Rmd file for the code.

```{r, echo=FALSE}

##############################################################
# Create edx set, validation set (final hold-out test set) ###
##############################################################

# Note: this process could take a couple of minutes

# loading libraries
library(tidyverse)
library(caret)
library(data.table)

# removing all files
rm(list=ls())

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")

movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(movieId),
                                           title = as.character(title),
                                           genres = as.character(genres))


movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding") # if using R 3.5 or earlier, use `set.seed(1)`
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

```
Nest, I save the files

```{r}
### saving the training and test sets ###
getwd()
setwd("H:/My Drive/sync/data analytics and machine learning/harvardx/Capstone/Github project/public/ml-10M100K")
saveRDS(movies, file="movies")
saveRDS(ratings, file="ratings")
saveRDS(edx, file="edx")
saveRDS(validation, file="validation")
saveRDS(movielens, file="movielens")
```

Now I examine the data by running some analyses and creating some plots, partly based on code provided in previous courses.

```{r}
### Exploring the training set ###
dim(edx)
names(edx)
head(edx)
summary(edx)
sum(is.na(edx)) # counting missing values

# counting the unique values
n_distinct(edx$userId) # users
n_distinct(edx$movieId) # movies
n_distinct(edx$rating) # ratings
n_distinct(edx$genres) # genres

# plotting the distributions of the ratings 
histogram(edx$rating)

# plotting the distribution of the ratings per movie
ratings_per_movie<-edx %>%
  count(movieId)
histogram(ratings_per_movie$n, breaks=30)
boxplot(ratings_per_movie$n)
summary(ratings_per_movie$n)

rm(ratings_per_movie) # removing the variable

# plotting the distribution of ratings per user
ratings_per_user<-edx %>%
  filter(!is.na(rating))  %>%
  count(userId)

histogram(ratings_per_user$n, breaks=30)
boxplot(ratings_per_user$n)
summary(ratings_per_user$n)

rm(ratings_per_user) # removing the variable

```



